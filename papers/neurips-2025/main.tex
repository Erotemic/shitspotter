\documentclass{article}
%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts

% Define conditions
\newif\ifnonanonymous
\newif\ifuseappendix
\newif\ifuseacknowledgement


% ====================
% CONDITIONAL SETTINGS
% ====================
\nonanonymoustrue % comment out to be anonymous
\useacknowledgementtrue % comment out to remove acknowledgements
\useappendixtrue % comment out to remove appendix
% ====================

\ifnonanonymous
\usepackage[nonatbib,final]{neurips_2025}
% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2025}
\else
%\usepackage{neurips_2025}
\usepackage[nonatbib,preprint]{neurips_2025}
\fi

\newcommand{\redact}[1]{%
    \ifnonanonymous
        #1% Show the original text if nonanonymous is true
    \else
        [redacted for peer review]% Redact if false
    \fi
}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, 
% e.g. with the file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete *.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you should be clear).
%\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
%\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}
%\usepackage{hyperref}
\usepackage[
  colorlinks=true,      % no boxes; color the text instead
  %linkcolor=black,      % section refs etc. remain black
  %urlcolor=blue!55!black,
  %citecolor=blue!55!black
]{hyperref}



% Include other packages here, before hyperref.
%\usepackage{stfloats}

\usepackage{graphicx}
%\usepackage{emoji}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{framed}
\usepackage{booktabs}
\usepackage{comment}
\usepackage{multicol}
\usepackage{makecell}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage{cclicenses}
\usepackage{xspace}
%\usepackage{enumitem}
\usepackage{pdfcomment} % provides \pdftooltip

\usepackage{floatrow}
\floatsetup[table]{capposition=top} % all tables: caption below



%\usepackage{url}            % simple URL typesetting
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}         % Can be removed after putting your text content
\usepackage[numbers]{natbib}
\usepackage{doi}
\usepackage{seqsplit}
\usepackage{placeins}


%% extra
\usepackage{listings}
\usepackage[table,xcdraw,dvipsnames]{xcolor}
\usepackage[toc]{appendix}

%\usepackage{fontspec}
%\setmainfont{TeX Gyre Termes} % Or another font you like

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\newcommand{\eg}{e.g.\@\xspace}
\newcommand{\ie}{i.e.\@\xspace}
\newcommand{\etal}{et~al.\@\xspace}
\newcommand{\etc}{etc.\@\xspace}
\newcommand{\aka}{a.k.a.\@\xspace}
\newcommand{\cf}{cf.\@\xspace}
\newcommand{\vs}{vs.\@\xspace}
\newcommand{\wrt}{w.r.t.\@\xspace}

% Capitalized (use at sentence start)
\newcommand{\Eg}{E.g.\@\xspace}
\newcommand{\Ie}{I.e.\@\xspace}
\newcommand{\Etal}{Et~al.\@\xspace}


\newcommand{\cotwo}{\ensuremath{\mathrm{CO_2}}}

%\newcommand{\ipfsgateway}{https://ipfs.io/ipfs/}
\newcommand{\ipfsgateway}{https://ipfs.io/ipfs/QmQonrckXZq37ZHDoRGN4xVBkqedvJRgYyzp2aBC5Ujpyp?autoadapt=0&requiresorigin=0&web3domain=0&immediatecontinue=1&magiclibraryconfirmation=0&redirectURL=}

% --- Helpers ---
% Takes CID as argument, shows it in monospace, links to ipfs.io
\newcommand{\ipfscid}[1]{\href{\ipfsgateway#1}{\texttt{\seqsplit{#1}}}}

\newcommand{\magnetlink}[1]{\href{magnet:?xt=urn:btih:#1}{\texttt{\seqsplit{magnet:?xt=urn:btih:#1}}}}

% Macro: \dockerimage{<url>}{<imagename>}
\newcommand{\dockerimage}[2]{%
  \href{#1}{\texttt{#2}}%
}

\ifnonanonymous
\newcommand{\repoBase}{https://github.com/Erotemic/scatspotter/blob/31f497e2586f0d1560b9bbd65415f9bd36a07585}
\else
% TODO: link to the anonymous version of the repo
\newcommand{\repoBase}{https://anonymous.4open.science/r/scatspotter-DD67}
\fi
\newcommand{\repolink}[2]{\href{\repoBase/#1}{\texttt{#2}}}

\newcommand{\linkwithtip}[3]{%
  \href{#1}{\pdftooltip{#3}{#2}}%
}

\newcommand{\ghlink}[1]{%
  \href{https://github.com/#1}{#1}
}

\newcommand{\hflink}[1]{%
  \href{https://huggingface.co/#1}{#1}
}

\newcommand{\YOLOPretrained}{
  \linkwithtip
  {https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt}
  {sha256 is b66df73be150f1025574b4399148815d5c510cf3d8f7fc7db216228e298132c6}
  {\texttt{v9-c.pt}}
}

\newcommand{\DINOPretrained}{
  \linkwithtip
  {https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth}
  {sha256 is 3b3ca2563c77c69f651d7bd133e97139c186df06231157a64c507099c52bc799}
  {\texttt{groundingdino\_swint\_ogc.pth}}
}

\newcommand{\MaskRCNNPretrained}{
  \linkwithtip
  {https://dl.fbaipublicfiles.com/detectron2/ImageNetPretrained/MSRA/R-50.pkl}
  {sha256 is 98f5aabca9d6bcc5d61d0517987356d710a8404e7ffe242caf1d8f343357b448}
  {\texttt{detectron2://ImageNetPretrained/MSRA/R-50.pkl}}
}


\title{``ScatSpotter'' --- A Dog Poop Detection Dataset}

\author{Jonathan Crall\\
Kitware\\
\texttt{jon.crall@kitware.com} \\
%{\tt\small erotemic@gmail.com}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
%\and
%Second Author\\
%Institution2\\
%First line of institution2 address\\
%{\tt\small secondauthor@i2.org}
}

\begin{document}
\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}

We introduce a new dataset containing phone images of dog feces, annotated with manually drawn or AI-assisted polygon labels.  Its over 9000 ``before/after/negative'' full resolution images contain 6000 polygon annotations.  The collection of images started in late 2020.  This paper focuses on two checkpoints from 2025-04-20 and 2024-07-03.  We train VIT, MaskRCNN, YOLO-v9, and Grounding DINO baseline models to explore the difficulty of the dataset.  The best model achieves a box-level average precision of 0.69 on a 691-image validation set and 0.70 on a small independently captured 121-image contributor test set.  Dataset snapshots are available through four different distribution methods: two centralized (Girder and HuggingFace) and two decentralized (IPFS and BitTorrent).  We study the trade-offs between distribution methods and discuss the feasibility of each with respect to reliably sharing open scientific data.  The code for experiments is \href{\repoBase}{hosted on GitHub}.  The data license is CC-BY 4.0.  Model weights are available with the dataset.  Experiment hardware, time, energy, and emissions are quantified.

% Keywords: poop, feces, dataset, dataset distribution, detection, segmentation, IPFS, BitTorrent, HuggingFace

%We train a baseline vision transformer to segment the objects of interest, exploring a grid of hyperparameters, and we evaluate their impact. 
%A phone application to detect poop with these models is being developed and 
%will be made freely available.
\end{abstract}

%%%%%%%%% BODY TEXT
\input{section1}
\input{section2}
\input{section3}
\input{section4}
\FloatBarrier
\input{section5}
%\FloatBarrier
\input{section6}

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieeenat_fullname}
\bibliography{citations}
}


\ifuseappendix
% WARNING: do not forget to delete the supplementary pages from your submission 
\include{appendix}
%\include{neurips_2025_checklist}
\fi


\begin{comment}
    %cd $HOME/code/shitspotter
    %python -m shitspotter.cli.coco_annotation_stats $HOME/data/dvc-repos/shitspotter_dvc/data.kwcoco.json \
    %    --dst_fpath $HOME/code/shitspotter/coco_annot_stats/stats.json \
    %    --dst_dpath $HOME/code/shitspotter/coco_annot_stats

    cd $HOME/code/shitspotter
    kwcoco plot_stats \
        $HOME/data/dvc-repos/shitspotter_dvc/data.kwcoco.json \
        --dst_fpath $HOME/code/shitspotter/coco_annot_stats2/stats.json \
        --dst_dpath $HOME/code/shitspotter/coco_annot_stats2

    SeeAlso:
    ~/code/shitspotter/experiments/geowatch-experiments/run_pixel_eval_on_vali_pipeline.sh
    ~/code/shitspotter/experiments/geowatch-experiments/run_pixel_eval_on_test_pipeline.sh
    ~/code/shitspotter/experiments/geowatch-experiments/run_pixel_eval_on_train_pipeline.sh

    python ~/code/shitspotter/dev/poc/estimate_train_resources.py

    See: ./localize_figures.sh


    Best Validation Model:
        /home/joncrall/data/dvc-repos/shitspotter_expt_dvc/training/toothbrush/joncrall/ShitSpotter/runs/shitspotter_scratch_20240618_noboxes_v7/lightning_logs/version_1/checkpoints/epoch=0089-step=122940-val_loss=0.019.ckpt.pt
        # Best Rank:  33.0 pyzvffmyjcrq
        Lives in /home/joncrall/data/dvc-repos/shitspotter_expt_dvc/_shitspotter_test_evals/eval/flat/heatmap_eval/heatmap_eval_id_0f613533/pxl_eval.json heatmap_eval           pyzvffmyjcrq    0.505110     0.912509
        

    Best Test Model:
        /home/joncrall/data/dvc-repos/shitspotter_expt_dvc/training/toothbrush/joncrall/ShitSpotter/runs/shitspotter_scratch_20240618_noboxes_v6/lightning_logs/version_0/checkpoints/epoch=0073-step=101084-val_loss=0.017.ckpt.pt
        is Rank 3 on the validation dataset.
    

    cd /home/joncrall/code/shitspotter/shitspotter_dvc
    geowatch spectra --src data.kwcoco.json --workers=16 --cache_dpath=_spectra_cache --dst spectra.png --bins 64 --valid_range=0:255
    cp spectra.png ~/code/shitspotter/papers/neurips-2025/figures/spectra.png

    /home/joncrall/code/shitspotter/papers/neurips-2025
    python -m shitspotter.ipfs pull .

\end{comment}

\end{document}


